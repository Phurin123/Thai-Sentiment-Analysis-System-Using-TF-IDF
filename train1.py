import re
import pandas as pd
import uuid
from datetime import datetime
import os

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
    f1_score,
)
import joblib
import matplotlib.pyplot as plt
import seaborn as sns


# === 1. Preprocessing function ===
def preprocess(text):
    """
    ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ preprocessing:
    - ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤-‡∏´‡∏•‡∏±‡∏á: ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤ null ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô
    - normalize whitespace: ‡∏£‡∏ß‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‚Üí ‡∏•‡∏î noise ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏°‡∏û‡πå
    - ‡πÑ‡∏°‡πà lowercase ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà/‡πÄ‡∏•‡πá‡∏Å
    - ‡πÑ‡∏°‡πà‡∏•‡∏ö emoji/slang ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏´‡πâ‡∏≤‡∏° over-cleaning
    """
    text = str(text).strip()
    text = re.sub(r"\s+", " ", text)  # normalize whitespace
    return text


# === 2. Load and prepare data ===
df = pd.read_csv("data/1.synthetic_wisesight_like_thai_sentiment_5000.csv")
df = df.rename(columns={"sentiment": "label"})
df["text"] = df["text"].apply(preprocess)

# === 3. Train-test split ===
X = df["text"]
y = df["label"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# === 4. Train model (WORD-LEVEL TF-IDF ‡∏ï‡∏≤‡∏° requirement) ===
vectorizer = TfidfVectorizer(
    analyzer="word",  # word-level
    ngram_range=(1, 2),  # unigram + bigram
    max_features=10000,
)
X_train_vec = vectorizer.fit_transform(X_train)
model = LogisticRegression(class_weight="balanced", max_iter=1000, random_state=42)
model.fit(X_train_vec, y_train)

# === 5. Generate UID for model version ===
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
uid = uuid.uuid4().hex[:8]
model_uid = f"{timestamp}_{uid}"

# === 6. Save model and vectorizer ===
os.makedirs("models", exist_ok=True)
model_path = f"models/sentiment_model_{model_uid}.joblib"
vectorizer_path = f"models/vectorizer_{model_uid}.joblib"

joblib.dump(model, model_path)
joblib.dump(vectorizer, vectorizer_path)

print(f"Model saved as: {model_path}")
print(f"Vectorizer saved as: {vectorizer_path}")

# === 7. Evaluation (‡πÄ‡∏î‡∏¥‡∏°) ===
X_test_vec = vectorizer.transform(X_test)
y_pred = model.predict(X_test_vec)

acc = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average="macro")
cm = confusion_matrix(y_test, y_pred)

print("\n=== EVALUATION RESULTS ===")
print("Accuracy:", round(acc, 4))
print("Macro-F1:", round(f1_macro, 4))
print("Confusion Matrix:\n", cm)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# === 7.1 ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ===
os.makedirs("results-Regress", exist_ok=True)
results_path = f"results-Regress/evaluation_{model_uid}.png"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á figure ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# --- ‡∏ã‡πâ‡∏≤‡∏¢: ‡πÅ‡∏™‡∏î‡∏á Accuracy ‡πÅ‡∏•‡∏∞ Macro-F1 ‡πÄ‡∏õ‡πá‡∏ô text ---
axes[0].axis("off")
metrics_text = (
    f"Model UID: {model_uid}\n\n" f"Accuracy: {acc:.4f}\n" f"Macro-F1: {f1_macro:.4f}"
)
axes[0].text(
    0.1,
    0.5,
    metrics_text,
    fontsize=14,
    verticalalignment="center",
    fontfamily="monospace",
)

# --- ‡∏Ç‡∏ß‡∏≤: Confusion Matrix heatmap ---
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    ax=axes[1],
    xticklabels=model.classes_,
    yticklabels=model.classes_,
)
axes[1].set_title("Confusion Matrix")
axes[1].set_xlabel("Predicted Label")
axes[1].set_ylabel("True Label")

# ‡∏à‡∏±‡∏î layout ‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏ä‡∏ô‡∏Å‡∏±‡∏ô
plt.tight_layout()
plt.savefig(results_path, dpi=150, bbox_inches="tight")
plt.close()  # ‡∏õ‡∏¥‡∏î figure ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô notebook ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πâ‡∏≤‡∏á‡πÉ‡∏ô memory

print(f"‚úÖ Saved evaluation results as image: {results_path}")

# === 9. Save misclassified examples to CSV for web deployment ===
ERRORS_OUTPUT_PATH = "data/error_examples.csv"
os.makedirs("data", exist_ok=True)
errors_df.head(10).to_csv(ERRORS_OUTPUT_PATH, index=False, encoding="utf-8")
print(f"‚úÖ Saved 10 misclassified examples to: {ERRORS_OUTPUT_PATH}")


# === 10. Error Analysis (‚â•3 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó) ===
def categorize_error(text, true_label, pred_label):
    # 1. Mixed signal
    neg_words = ["‡πÑ‡∏°‡πà", "‡πÅ‡∏°‡πà‡∏á", "‡πÅ‡∏¢‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏¥‡∏î", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á"]
    pos_words = ["‡∏î‡∏µ‡∏°‡∏≤‡∏Å", "‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à", "‡πÇ‡∏≠‡πÄ‡∏Ñ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ñ‡∏≤‡∏î", "‡∏ä‡∏≠‡∏ö"]
    has_neg = any(w in text for w in neg_words)
    has_pos = any(w in text for w in pos_words)
    if has_neg and has_pos:
        return "Mixed Signal / Ambiguity"

    # 2. Sarcasm / Informal
    if any(emoji in text for emoji in ["üò§", "üôÑ", "üòí", "üôÇ", "üòä"]) or "‡πÅ‡∏°‡πà‡∏á" in text:
        return "Sarcasm / Informal Expression"

    # 3. Ambiguous neutral
    neutral_phrases = ["‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô", "‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥", "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏¢‡πà ‡πÅ‡∏ï‡πà‡∏Å‡πá‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏î‡∏µ"]
    if any(phrase in text for phrase in neutral_phrases):
        return "Ambiguous Neutral Expression"

    return "Other"


errors_df["error_type"] = errors_df.apply(
    lambda row: categorize_error(row["text"], row["true_label"], row["pred_label"]),
    axis=1,
)

print("\n=== ERROR ANALYSIS (Grouped by Type) ===")
error_counts = errors_df["error_type"].value_counts()
print(error_counts)

most_common_error = error_counts.idxmax()
print(
    f"\nMost common error type: '{most_common_error}' ({error_counts[most_common_error]} cases)"
)

if most_common_error == "Mixed Signal / Ambiguity":
    suggestion = "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ detect negation ‡πÅ‡∏•‡∏∞ contextual cues ‡∏î‡πâ‡∏ß‡∏¢ rule-based ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• sequence ‡πÄ‡∏ä‡πà‡∏ô BERT"
elif most_common_error == "Sarcasm / Informal Expression":
    suggestion = "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ normalize emoji ‡πÅ‡∏•‡∏∞ slang ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á ‡∏´‡∏£‡∏∑‡∏≠ fine-tune ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• informal Thai"
elif most_common_error == "Ambiguous Neutral Expression":
    suggestion = (
        "‡∏™‡∏£‡πâ‡∏≤‡∏á class 'Neutral' ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ threshold-based confidence ‡πÅ‡∏ó‡∏ô hard label"
    )
else:
    suggestion = "‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏•‡∏∂‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô transformer-based model"

print(f"\nSuggested improvement: {suggestion}")
